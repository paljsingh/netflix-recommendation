{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning parameters\n",
    "users_per_chunk=1000                # Number of users per batch.\n",
    "similar_users_count = 2             # How many similar users to be found ?\n",
    "number_of_recommended_movies = 5    # How many movies to be recommended per user?\n",
    "rating_threshold = 4                # only consider movies with ratings >= N for recommendation.\n",
    "minimum_movies_rated = 4            # consider only users who have rated at least N movies.\n",
    "\n",
    "output_file = \"./recommendation.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_movie_titles():\n",
    "    rows = []\n",
    "    keys = ['movie_id', 'release_year', 'movie_title']\n",
    "    with open('movie_titles.csv', encoding='iso-8859-1') as f:\n",
    "      for line in f.read().splitlines():\n",
    "        rows.append(dict(zip(keys, line.split(',', 2))))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def get_ratings_data():\n",
    "    start_time = time.time()\n",
    "\n",
    "    sorted_user_ratings_file = \"sorted_user_ratings.csv\"\n",
    "    if not os.path.isfile(sorted_user_ratings_file):\n",
    "\n",
    "        unsorted_user_ratings_file = \"unsorted_user_ratings.csv\"\n",
    "        if not os.path.isfile(unsorted_user_ratings_file):\n",
    "            print(\"combining movie ratings data...\")\n",
    "            files = ['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt']\n",
    "            movie_id=-1\n",
    "\n",
    "            with open(unsorted_user_ratings_file, \"w+\", encoding='iso-8859-1') as f_out:\n",
    "                f_out.write(\"user_id,movie_id,rating\\n\")\n",
    "                for file in files:\n",
    "                    print(\"{}\".format(file))\n",
    "                    with open(file, 'r', encoding='iso-8859-1') as f:\n",
    "                        for line in f.read().splitlines():\n",
    "                            if line.endswith(':'):\n",
    "                                movie_id = line.split(':')[0]\n",
    "                            else:\n",
    "                                fields = line.split(',')\n",
    "                                f_out.write(\"{},{},{}\\n\".format(fields[0], movie_id, fields[1]))\n",
    "\n",
    "        print(\"saving sorted user ratings to disk...\")\n",
    "        df = pd.read_csv(unsorted_user_ratings_file, encoding='iso-8859-1')\n",
    "        \n",
    "        df.sort_values('user_id', ascending=True, inplace=True, kind='quicksort')\n",
    "        df.to_csv(sorted_user_ratings_file, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(sorted_user_ratings_file, encoding='iso-8859-1')\n",
    "\n",
    "\n",
    "    end_time = time.time() \n",
    "    print(\"... took {:.3f} seconds\".format(end_time - start_time))\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_qualifying():\n",
    "    movie_id = user_id = None\n",
    "    user_ids = set()\n",
    "    movie_user_mapping = defaultdict(list)\n",
    "    with open(\"./qualifying.txt\", 'r') as f:\n",
    "        for line in f.read().splitlines():\n",
    "            if line.endswith(':'):\n",
    "                movie_id = line\n",
    "            else:\n",
    "                user_id, rating_date = line.split(',')\n",
    "                user_ids.add(user_id)\n",
    "                movie_user_mapping[movie_id].append(user_id)\n",
    "    print(len(user_ids))\n",
    "    print(len(movie_user_mapping))\n",
    "    print(list(islice(movie_user_mapping.items(), 5)))\n",
    "    return user_ids, movie_user_mapping\n",
    "    \n",
    "\n",
    "def get_random_users():\n",
    "    c = list(unique_users)\n",
    "    return random.sample(c, users_per_chunk)\n",
    "\n",
    "\n",
    "def get_recommended_movie_ids(user_id, other_users_ids):\n",
    "    rated_by_me = set(df_subset[ (df_subset['user_id']==user_id)]['movie_id'])\n",
    "    \n",
    "#     print(\"rated by {}: {}\".format(user_id, rated_by_me))\n",
    "    rated_by_others = list()\n",
    "    for uid in other_users_ids:\n",
    "        rated_by_others.append(set(df_subset[ (df_subset['user_id']==uid) & (df_subset['rating'] >= rating_threshold) ]['movie_id']))\n",
    "\n",
    "#     print(\"rated by {}: {}\".format(other_users_ids, rated_by_others))\n",
    "\n",
    "    rated_by_others_all = set.union(*rated_by_others)\n",
    "#     print(\"all movies rated by {}: {}\".format(other_users_ids, rated_by_others_all))\n",
    "\n",
    "    # movies not rated by me, but rated by other (similar users)\n",
    "    not_rated_by_me = set.difference(rated_by_others_all, rated_by_me)\n",
    "#     print(\"not rated by {}: {}\".format(user_id, not_rated_by_me))\n",
    "\n",
    "    new_ratings = dict()\n",
    "    for movie_id in not_rated_by_me:\n",
    "        # add new rating by this user = mean of nearest user's ratings.\n",
    "        others_ratings = []\n",
    "        for ouid in other_users_ids:\n",
    "#             rated = df[ (df_subset['user_id']== ouid ) & (df_subset['movie_id'] == movie_id ) ]\n",
    "            rated = df_subset[ (df_subset['user_id']== ouid ) & (df_subset['movie_id'] == movie_id ) ]\n",
    "\n",
    "            if not rated.empty:\n",
    "                others_ratings.append(rated.iloc[0]['rating'])\n",
    "#         print(\"ratings for movie_id {} by {}: {}\".format(movie_id, other_users_ids, others_ratings))\n",
    "        new_rating = np.mean(others_ratings)\n",
    "\n",
    "#       df_subset[ (df_subset['user_id']==user_id) & (df_subset['movie_id']==movie_id) ]['rating'] = new_rating\n",
    "        # also save this in a temp dict for top 5 picks.\n",
    "        new_ratings[movie_id] = new_rating\n",
    "#         print(\"new rating for movie {} : {:.1f}\".format(movie_id, new_rating))\n",
    "\n",
    "    # pick top N movies from the not_rated_by_me \n",
    "    rec_movies = heapq.nlargest(number_of_recommended_movies, new_ratings, key=new_ratings.get)    \n",
    "    return rec_movies\n",
    "\n",
    "\n",
    "def get_movie_titles(movie_ids):\n",
    "    return [ df_movie[ df_movie['movie_id']==x ].iloc[0]['movie_title'] for x in movie_ids ]\n",
    "    \n",
    "\n",
    "def get_similarity_matrix(user_ratings_normalized):\n",
    "    sparse_matrix = sparse.csr_matrix(user_ratings_normalized)\n",
    "    similarities_sparse = cosine_similarity(sparse_matrix.transpose(), dense_output=False)\n",
    "    similarities_sparse.setdiag(-1)   # set diagonal entries to lowest values to exclude self similarity.\n",
    "    return similarities_sparse\n",
    "\n",
    "\n",
    "def get_similar_user_ids(i, user_id, similarities_sparse):\n",
    "    col_vals = similarities_sparse.getrow(i).toarray().tolist()[0]\n",
    "\n",
    "    # N most similar users (last element is the most similar)\n",
    "    similar_records = np.argsort(col_vals)[-similar_users_count:]\n",
    "    similar_user_ids = [user_ids[similar_records[j]] for j in range(len(similar_records)-1, -1, -1)]\n",
    "#     similarity_score = heapq.nlargest(similar_users_count, col_vals)\n",
    "#     return similar_user_ids, similarity_score\n",
    "    return similar_user_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie = read_movie_titles()\n",
    "df_movie = df_movie.astype({'movie_id': 'int16', 'movie_title': 'str'})\n",
    "df_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_ratings_data()\n",
    "df = df.astype({'user_id': 'int32', 'movie_id': 'int16', 'rating': 'int8'})\n",
    "\n",
    "df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = df['user_id'].unique()\n",
    "unique_movies = df['movie_id'].unique()\n",
    "print(\"unique users: {}, unique movies: {}\".format(len(unique_users), len(unique_movies)))\n",
    "print(\"total records: {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output will be written to {}\".format(output_file))\n",
    "\n",
    "with open(output_file, 'w', buffering=1) as f_out:\n",
    "    while len(df) > 0:\n",
    "        # take random N users (1000 by default)\n",
    "        user_ids = get_random_users()\n",
    "        \n",
    "        # create a subset dataframe\n",
    "        df_subset = df[ df['user_id'].isin(user_ids)]\n",
    "        \n",
    "        # remove these users from original dataframe, so we don't process them again.\n",
    "        df = df[~df['user_id'].isin(user_ids)]\n",
    "\n",
    "        # get user ratings\n",
    "        user_ratings = df_subset.pivot(columns=['user_id'], index='movie_id', values='rating')\n",
    "\n",
    "        # normalize user ratings around 0.\n",
    "        user_ratings_normalized = round(user_ratings.subtract(user_ratings.mean(axis=0), axis=1))\n",
    "        # drop any users that have rated only N or less movies.\n",
    "        user_ratings_normalized = user_ratings_normalized.dropna(thresh=minimum_movies_rated,axis=1).fillna(0)\n",
    "        print(\"randomly chosen {} users\".format(user_ratings_normalized.shape[1]))\n",
    "\n",
    "        # compute similarity matrix using cosine similarity, obtain a sparse matrix.\n",
    "        similarities_sparse = get_similarity_matrix(user_ratings_normalized)\n",
    "\n",
    "        # iterate the similarity matrix and find N most similar users for each user.\n",
    "        for i in range(similarities_sparse.shape[1]):\n",
    "            user_id = user_ids[i]\n",
    "#             similar_user_ids, similarity_score = get_similar_user_ids(i, user_id, similarities_sparse)\n",
    "            similar_user_ids = get_similar_user_ids(i, user_id, similarities_sparse)\n",
    "            recommended_movies = get_recommended_movie_ids(user_id, similar_user_ids)\n",
    "            recommended_movie_titles = get_movie_titles(recommended_movies)\n",
    "\n",
    "            print(\"{} \".format(user_id), end='')\n",
    "\n",
    "#             print(\"user_id: {}, similar users: {}, score: {}\".format(user_id, similar_user_ids, similarity_score))\n",
    "#             print(\"recommended movies: {}\".format(recommended_movie_titles))\n",
    "#             print(\"---\")\n",
    "            f_out.write(\"user_id: {}\\n\".format(user_id))\n",
    "            f_out.write(\"{}\".format(\"\\n\".join(recommended_movie_titles)))\n",
    "            f_out.write('\\n---\\n')\n",
    "            \n",
    "#         response = input(\"continue? \")\n",
    "#         if response == 'n' or response == 'N':\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
