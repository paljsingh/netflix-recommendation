{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_method='svd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning parameters for recommendation via cosine similarity...\n",
    "users_per_iteration=1000                # Number of users per batch.\n",
    "similar_users_count = 2             # How many similar users to be found ?\n",
    "number_of_recommended_movies = 5    # How many movies to be recommended per user?\n",
    "rating_threshold = 4                # only consider movies with ratings >= N for recommendation.\n",
    "minimum_movies_rated = 4            # consider only users who have rated at least N movies.\n",
    "\n",
    "output_file = \"./recommendations.txt\"\n",
    "csv_files = ['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt']\n",
    "data_types = {'user_id': 'int32', 'movie_id': 'int16', 'rating': 'int8'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning parameters for svd based movie recommendation...\n",
    "benchmark_quantile = 0.7    # do not consider movies having less than 70 percentile votes\n",
    "records_per_iteration=1000                # Number of users per batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_movie_titles():\n",
    "    rows = []\n",
    "    keys = ['movie_id', 'release_year', 'movie_title']\n",
    "    with open('movie_titles.csv', encoding='iso-8859-1') as f:\n",
    "      for line in f.read().splitlines():\n",
    "        rows.append(dict(zip(keys, line.split(',', 2))))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def get_ratings_data():\n",
    "    start_time = time.time()\n",
    "\n",
    "    sorted_user_ratings_file = \"sorted_user_ratings.csv\"\n",
    "    if not os.path.isfile(sorted_user_ratings_file):\n",
    "\n",
    "        unsorted_user_ratings_file = \"unsorted_user_ratings.csv\"\n",
    "        if not os.path.isfile(unsorted_user_ratings_file):\n",
    "            print(\"combining movie ratings data...\")\n",
    "            movie_id=-1\n",
    "\n",
    "            with open(unsorted_user_ratings_file, \"w+\", encoding='iso-8859-1') as f_out:\n",
    "                f_out.write(\"user_id,movie_id,rating\\n\")\n",
    "                for file in csv_files:\n",
    "                    print(\"{}\".format(file))\n",
    "                    with open(file, 'r', encoding='iso-8859-1') as f:\n",
    "                        for line in f.read().splitlines():\n",
    "                            if line.endswith(':'):\n",
    "                                movie_id = line.split(':')[0]\n",
    "                            else:\n",
    "                                fields = line.split(',')\n",
    "                                f_out.write(\"{},{},{}\\n\".format(fields[0], movie_id, fields[1]))\n",
    "\n",
    "        print(\"saving sorted user ratings to disk...\")\n",
    "        df = pd.read_csv(unsorted_user_ratings_file, encoding='iso-8859-1', dtype = data_types)\n",
    "        \n",
    "        df.sort_values('user_id', ascending=True, inplace=True, kind='quicksort')\n",
    "        df.to_csv(sorted_user_ratings_file, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(sorted_user_ratings_file, encoding='iso-8859-1', dtype = data_types)\n",
    "\n",
    "\n",
    "    end_time = time.time() \n",
    "    print(\"... took {:.3f} seconds\".format(end_time - start_time))\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_qualifying():\n",
    "    movie_id = user_id = None\n",
    "    user_ids = set()\n",
    "    movie_user_mapping = defaultdict(list)\n",
    "    with open(\"./qualifying.txt\", 'r') as f:\n",
    "        for line in f.read().splitlines():\n",
    "            if line.endswith(':'):\n",
    "                movie_id = line\n",
    "            else:\n",
    "                user_id, rating_date = line.split(',')\n",
    "                user_ids.add(user_id)\n",
    "                movie_user_mapping[movie_id].append(user_id)\n",
    "    print(len(user_ids))\n",
    "    print(len(movie_user_mapping))\n",
    "    print(list(islice(movie_user_mapping.items(), 5)))\n",
    "    return user_ids, movie_user_mapping\n",
    "    \n",
    "\n",
    "def get_random_users():\n",
    "    c = list(unique_users)\n",
    "    return random.sample(c, users_per_iteration)\n",
    "\n",
    "\n",
    "def get_recommended_movie_ids(user_id, other_users_ids):\n",
    "    rated_by_me = set(df_subset[ (df_subset['user_id']==user_id)]['movie_id'])\n",
    "    \n",
    "#     print(\"rated by {}: {}\".format(user_id, rated_by_me))\n",
    "    rated_by_others = list()\n",
    "    for uid in other_users_ids:\n",
    "        rated_by_others.append(set(df_subset[ (df_subset['user_id']==uid) & (df_subset['rating'] >= rating_threshold) ]['movie_id']))\n",
    "\n",
    "#     print(\"rated by {}: {}\".format(other_users_ids, rated_by_others))\n",
    "\n",
    "    rated_by_others_all = set.union(*rated_by_others)\n",
    "#     print(\"all movies rated by {}: {}\".format(other_users_ids, rated_by_others_all))\n",
    "\n",
    "    # movies not rated by me, but rated by other (similar users)\n",
    "    not_rated_by_me = set.difference(rated_by_others_all, rated_by_me)\n",
    "#     print(\"not rated by {}: {}\".format(user_id, not_rated_by_me))\n",
    "\n",
    "    new_ratings = dict()\n",
    "    for movie_id in not_rated_by_me:\n",
    "        # add new rating by this user = mean of nearest user's ratings.\n",
    "        others_ratings = []\n",
    "        for ouid in other_users_ids:\n",
    "#             rated = df[ (df_subset['user_id']== ouid ) & (df_subset['movie_id'] == movie_id ) ]\n",
    "            rated = df_subset[ (df_subset['user_id']== ouid ) & (df_subset['movie_id'] == movie_id ) ]\n",
    "\n",
    "            if not rated.empty:\n",
    "                others_ratings.append(rated.iloc[0]['rating'])\n",
    "#         print(\"ratings for movie_id {} by {}: {}\".format(movie_id, other_users_ids, others_ratings))\n",
    "        new_rating = np.mean(others_ratings)\n",
    "\n",
    "#       df_subset[ (df_subset['user_id']==user_id) & (df_subset['movie_id']==movie_id) ]['rating'] = new_rating\n",
    "        # also save this in a temp dict for top 5 picks.\n",
    "        new_ratings[movie_id] = new_rating\n",
    "#         print(\"new rating for movie {} : {:.1f}\".format(movie_id, new_rating))\n",
    "\n",
    "    # pick top N movies from the not_rated_by_me \n",
    "    rec_movies = heapq.nlargest(number_of_recommended_movies, new_ratings, key=new_ratings.get)    \n",
    "    return rec_movies\n",
    "\n",
    "\n",
    "def get_movie_titles(movie_ids):\n",
    "    return [ df_movie[ df_movie['movie_id']==x ].iloc[0]['movie_title'] for x in movie_ids ]\n",
    "    \n",
    "\n",
    "def get_similarity_matrix(user_ratings_normalized):\n",
    "    sparse_matrix = sparse.csr_matrix(user_ratings_normalized)\n",
    "    similarities_sparse = cosine_similarity(sparse_matrix.transpose(), dense_output=False)\n",
    "    similarities_sparse.setdiag(-1)   # set diagonal entries to lowest values to exclude self similarity.\n",
    "    return similarities_sparse\n",
    "\n",
    "\n",
    "def get_similar_user_ids(i, user_id, similarities_sparse):\n",
    "    col_vals = similarities_sparse.getrow(i).toarray().tolist()[0]\n",
    "\n",
    "    # N most similar users (last element is the most similar)\n",
    "    similar_records = np.argsort(col_vals)[-similar_users_count:]\n",
    "    similar_user_ids = [user_ids[similar_records[j]] for j in range(len(similar_records)-1, -1, -1)]\n",
    "#     similarity_score = heapq.nlargest(similar_users_count, col_vals)\n",
    "#     return similar_user_ids, similarity_score\n",
    "    return similar_user_ids\n",
    "\n",
    "\n",
    "def plot_ratings():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = sns.countplot(x='rating', data=df)\n",
    "    plt.tick_params(labelsize=15)\n",
    "    plt.title(\"Rating Distribution\")\n",
    "    plt.xlabel(\"Number of Ratings\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_cosine_similarity():\n",
    "    with open(output_file, 'w', buffering=1) as f_out:\n",
    "        while len(df) > 0:\n",
    "            # take random N users (1000 by default)\n",
    "            user_ids = get_random_users()\n",
    "\n",
    "            # create a subset dataframe\n",
    "            df_subset = df[ df['user_id'].isin(user_ids)]\n",
    "\n",
    "            # remove these users from original dataframe, so we don't process them again.\n",
    "            df = df[~df['user_id'].isin(user_ids)]\n",
    "\n",
    "\n",
    "            # get user ratings\n",
    "            user_ratings = df_subset.pivot(columns=['user_id'], index='movie_id', values='rating')\n",
    "\n",
    "            # normalize user ratings around 0.\n",
    "            user_ratings_normalized = round(user_ratings.subtract(user_ratings.mean(axis=0), axis=1))\n",
    "            # drop any users that have rated only N or less movies.\n",
    "            user_ratings_normalized = user_ratings_normalized.dropna(thresh=minimum_movies_rated,axis=1).fillna(0)\n",
    "            print(\"randomly chosen {} users\".format(user_ratings_normalized.shape[1]))\n",
    "\n",
    "            # compute similarity matrix using cosine similarity, obtain a sparse matrix.\n",
    "            similarities_sparse = get_similarity_matrix(user_ratings_normalized)\n",
    "\n",
    "            # iterate the similarity matrix and find N most similar users for each user.\n",
    "            for i in range(similarities_sparse.shape[1]):\n",
    "                user_id = user_ids[i]\n",
    "        #             similar_user_ids, similarity_score = get_similar_user_ids(i, user_id, similarities_sparse)\n",
    "                similar_user_ids = get_similar_user_ids(i, user_id, similarities_sparse)\n",
    "                recommended_movies = get_recommended_movie_ids(user_id, similar_user_ids)\n",
    "                recommended_movie_titles = get_movie_titles(recommended_movies)\n",
    "\n",
    "                print(\"{} \".format(user_id), end='')\n",
    "\n",
    "        #             print(\"user_id: {}, similar users: {}, score: {}\".format(user_id, similar_user_ids, similarity_score))\n",
    "        #             print(\"recommended movies: {}\".format(recommended_movie_titles))\n",
    "        #             print(\"---\")\n",
    "                f_out.write(\"user_id: {}\\n\".format(user_id))\n",
    "                f_out.write(\"{}\".format(\"\\n\".join(recommended_movie_titles)))\n",
    "                f_out.write('\\n---\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_svd():\n",
    "    f = ['count','mean']\n",
    "\n",
    "    user_ids = get_random_users()\n",
    "\n",
    "    df_subset = pd.read_csv('./unsorted_user_ratings.csv')[:records_per_iteration]\n",
    "\n",
    "    df_movie_summary = df_subset.groupby('movie_id')['rating'].agg(f)\n",
    "    df_movie_summary.index = df_movie_summary.index.map(int)\n",
    "    movie_benchmark = round(df_movie_summary['count'].quantile(0.7),0)\n",
    "    drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
    "\n",
    "    print('Movie minimum times of review: {}'.format(movie_benchmark))\n",
    "\n",
    "    df_cust_summary = df_subset.groupby('user_id')['rating'].agg(f)\n",
    "    df_cust_summary.index = df_cust_summary.index.map(int)\n",
    "    cust_benchmark = round(df_cust_summary['count'].quantile(0.7),0)\n",
    "    drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
    "    print(cust_benchmark)\n",
    "\n",
    "    print('Customer minimum times of review: {}'.format(cust_benchmark))\n",
    "\n",
    "    reader = Reader()\n",
    "    svd = SVD()\n",
    "    data = Dataset.load_from_df(df_subset, reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    svd.fit(trainset)\n",
    "\n",
    "\n",
    "    df_watched = df_subset[(df_subset['user_id'] == 1110480) & (df_subset['rating'] == 5)]\n",
    "    df_watched = df_watched.set_index('movie_id')\n",
    "    df_watched = df_watched.join(df_movie)['movie_title']\n",
    "\n",
    "    user_recommend = df_movie.copy()\n",
    "    user_recommend = user_recommend.reset_index()\n",
    "    user_recommend = user_recommend[~user_recommend['movie_id'].isin(drop_movie_list)]\n",
    "\n",
    "    user_recommend['estimate_score'] = user_recommend['movie_id'].apply(lambda x: svd.predict(1110480, x).est)\n",
    "\n",
    "    user_recommend = user_recommend.sort_values('estimate_score', ascending=False)\n",
    "    print(user_recommend.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>release_year</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>17766</td>\n",
       "      <td>2002</td>\n",
       "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>17767</td>\n",
       "      <td>2004</td>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>17768</td>\n",
       "      <td>2000</td>\n",
       "      <td>Epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>17769</td>\n",
       "      <td>2003</td>\n",
       "      <td>The Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>17770</td>\n",
       "      <td>2003</td>\n",
       "      <td>Alien Hunter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17770 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id release_year  \\\n",
       "0             1         2003   \n",
       "1             2         2004   \n",
       "2             3         1997   \n",
       "3             4         1994   \n",
       "4             5         2004   \n",
       "...         ...          ...   \n",
       "17765     17766         2002   \n",
       "17766     17767         2004   \n",
       "17767     17768         2000   \n",
       "17768     17769         2003   \n",
       "17769     17770         2003   \n",
       "\n",
       "                                             movie_title  \n",
       "0                                        Dinosaur Planet  \n",
       "1                             Isle of Man TT 2004 Review  \n",
       "2                                              Character  \n",
       "3                           Paula Abdul's Get Up & Dance  \n",
       "4                               The Rise and Fall of ECW  \n",
       "...                                                  ...  \n",
       "17765  Where the Wild Things Are and Other Maurice Se...  \n",
       "17766                  Fidel Castro: American Experience  \n",
       "17767                                              Epoch  \n",
       "17768                                        The Company  \n",
       "17769                                       Alien Hunter  \n",
       "\n",
       "[17770 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie = read_movie_titles()\n",
    "df_movie = df_movie.astype({'movie_id': 'int16', 'movie_title': 'str'})\n",
    "df_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ebf534c44bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ratings_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9a8752622b1d>\u001b[0m in \u001b[0;36mget_ratings_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_user_ratings_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_user_ratings_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/paljsingh/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/paljsingh/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/paljsingh/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/paljsingh/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "df = get_ratings_data()\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = df['user_id'].unique()\n",
    "unique_movies = df['movie_id'].unique()\n",
    "print(\"unique users: {}, unique movies: {}\".format(len(unique_users), len(unique_movies)))\n",
    "print(\"total records: {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output will be written to ./recommendations.txt\n",
      "Movie minimum times of review: 404.0\n",
      "1.0\n",
      "Customer minimum times of review: 1.0\n",
      "       index  movie_id release_year                              movie_title  \\\n",
      "0          0         1         2003                          Dinosaur Planet   \n",
      "11845  11845     11846         1985                           Prizzi's Honor   \n",
      "11851  11851     11852         1991                Return to the Blue Lagoon   \n",
      "11850  11850     11851         1946                             The Yearling   \n",
      "11849  11849     11850         2003  Dumb and Dumberer: When Harry Met Lloyd   \n",
      "\n",
      "       estimate_score  \n",
      "0            3.780306  \n",
      "11845        3.686000  \n",
      "11851        3.686000  \n",
      "11850        3.686000  \n",
      "11849        3.686000  \n"
     ]
    }
   ],
   "source": [
    "print(\"output will be written to {}\".format(output_file))\n",
    "\n",
    "if recommender_method == 'svd':\n",
    "    recommend_by_svd()\n",
    "else:\n",
    "    recommend_by_cosine_similarity()\n",
    "\n",
    "        \n",
    "        \n",
    "#         response = input(\"continue? \")\n",
    "#         if response == 'n' or response == 'N':\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
